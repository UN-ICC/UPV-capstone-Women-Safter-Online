{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82da2f31-9480-415e-98ac-4ce60a0ba163",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Models Development\n",
    "### Binary and Multiclass Classification using Hugging Face, RayTune and Weights&Biases\n",
    "\n",
    " **Authors:** √Ålvaro D. G√≥mez Ant√≥n, Sabah Serhir Serhir, Elisa M. Ramos Monsoriu, Lautaro Paniati Altamirano, Estefania Sol√≠s Valverde, Alba Valverde Porcar\n",
    "\n",
    "<br></br>\n",
    "\n",
    "<div style=\"text-align: right\"><i>Explaining Online Sexism: Language Models and a Mexican Perspective</i></div>\n",
    "    \n",
    "<div style=\"text-align: right\">A Capstone Project by United Nations International Computing Centre (<a href=\"https://www.unicc.org/\">UNICC</a>) and Universitat Polit√®cnica de Val√®ncia (<a href=\"https://www.upv.es/es\">UPV</a>) </div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d30cec-d92b-405d-b39a-487e28c4a5b4",
   "metadata": {},
   "source": [
    "In this notebook, we embark on a journey to detect and classify sexism content in Spanish tweets. With the rise of social media, online sexism has become a pressing issue that requires effective monitoring and intervention. Leveraging the power of deep learning and language models, we aim to develop a robust classification system that can accurately identify and categorize sexist content in Spanish text.\n",
    "\n",
    "To tackle our objectives, we adopt a fine-tuning approach using a pretrained large language model (LLM). However, we take a unique path by exploring two distinct training strategies. The first approach involves utilizing only the original Spanish data, while the second incorporates both the original and translated data.\n",
    "\n",
    "The incorporation of translated data serves a crucial purpose ‚Äì to evaluate the impact of language translation on the classification task. Deep learning models, including LLMs, often exhibit improved performance with larger training datasets. However, preserving the original meaning of the text becomes a challenge during translation. Conventional translation tools may struggle to retain the intended meaning, potentially affecting the performance of our models.\n",
    "\n",
    "Thus, we set out to investigate whether large language models, such as GPT-3.5, can effectively translate text while maintaining its meaning and valuable information. If the results obtained using the translated data are equal to or better than those achieved solely with Spanish data, it would signify the capacity of these models to preserve meaning during translation. Such a discovery would be significant, as it suggests a promising solution to overcome data scarcity in specific-language natural language processing (NLP) problems. Currently, languages other than widely used ones like English often lack sufficient data, limiting the full potential of artificial intelligence and machine learning in these contexts.\n",
    "\n",
    "Conversely, if the performance using translated data is worse, it would indicate that large language models have not yet reached their full efficiency in overcoming language barriers. Understanding these outcomes will provide valuable insights into the capabilities and limitations of language models in addressing the challenges of online sexism in Spanish.\n",
    "\n",
    "Throughout this notebook, we will guide you through the steps of training and fine-tuning our models using the ü§ó Hugging Face ecosystem, analyzing their performance using both aforementioned approaches, optimizing hyperparameters with RayTune, and evaluating the results using the Weights&Biases platform. By the end, we aim to contribute to the development of effective tools for combating online sexism, promoting safer digital spaces, and fostering inclusive communities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6830e80c-7d3a-4ed9-9aca-5e4985f76100",
   "metadata": {},
   "source": [
    "**Requirements**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f72fe20-b727-47fb-bb0a-8cdc20a602bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install datasets\n",
    "!pip install evaluate\n",
    "#!pip install accelerate\n",
    "!pip install git+https://github.com/huggingface/accelerate\n",
    "!pip install 'ray[tune]'\n",
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afa290a-2005-47cf-9afe-f8da62bf9eab",
   "metadata": {},
   "source": [
    "## The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a92c33-4698-40f4-b658-7fcc65f27797",
   "metadata": {},
   "source": [
    "Our dataset consists of labeled tweets, differentiating between sexism and non-sexism, with additional categorization of the specific types of sexism displayed. It encompasses original Spanish tweets collected from diverse sources, as well as translated tweets that were originally in English and subsequently translated to Mexican Spanish using GPT-3.5. Mexican Spanish because the aim of this modelos is to be used in the MExican scenario. For a more comprehensive understanding of the data preparation steps, we encourage you to refer to the \"1-data-preparation.ipynb\" notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b2ee402-bec0-4108-a5c5-3b5aa88a6bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_id</th>\n",
       "      <th>text</th>\n",
       "      <th>sexist</th>\n",
       "      <th>type</th>\n",
       "      <th>language</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>no sab√≠a que \"random\" era una opci√≥n.</td>\n",
       "      <td>0</td>\n",
       "      <td>non-sexist</td>\n",
       "      <td>es-mx</td>\n",
       "      <td>callme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>los dos √∫ltimos deber√≠an haberse ido.</td>\n",
       "      <td>0</td>\n",
       "      <td>non-sexist</td>\n",
       "      <td>es-mx</td>\n",
       "      <td>callme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>\"ladyboner\" merece mucho m√°s cr√©dito que \"dude...</td>\n",
       "      <td>0</td>\n",
       "      <td>non-sexist</td>\n",
       "      <td>es-mx</td>\n",
       "      <td>callme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>a partir de ahora se llamar√° \"sourpuss\".</td>\n",
       "      <td>0</td>\n",
       "      <td>non-sexist</td>\n",
       "      <td>es-mx</td>\n",
       "      <td>callme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>tarah w sacrific√≥ a varias mujeres para ganar ...</td>\n",
       "      <td>0</td>\n",
       "      <td>non-sexist</td>\n",
       "      <td>es-mx</td>\n",
       "      <td>callme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58757</th>\n",
       "      <td>1047687262455177217</td>\n",
       "      <td>yo no puedo darte luz todos los d√≠as, pero si ...</td>\n",
       "      <td>0</td>\n",
       "      <td>non-sexist</td>\n",
       "      <td>es</td>\n",
       "      <td>metwo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58758</th>\n",
       "      <td>1064482731739045888</td>\n",
       "      <td>que bien! aunque digan que las mujeres no debe...</td>\n",
       "      <td>0</td>\n",
       "      <td>non-sexist</td>\n",
       "      <td>es</td>\n",
       "      <td>metwo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58759</th>\n",
       "      <td>1040584804536856577</td>\n",
       "      <td>y misoginia las pelotas no quiero que vengas a...</td>\n",
       "      <td>0</td>\n",
       "      <td>non-sexist</td>\n",
       "      <td>es</td>\n",
       "      <td>metwo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58760</th>\n",
       "      <td>1051458429280235520</td>\n",
       "      <td>\"imaginen el tipo de sociedad mojigata y castr...</td>\n",
       "      <td>0</td>\n",
       "      <td>non-sexist</td>\n",
       "      <td>es</td>\n",
       "      <td>metwo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58761</th>\n",
       "      <td>1020717495605489673</td>\n",
       "      <td>por favor pase a la historia como una mujer qu...</td>\n",
       "      <td>0</td>\n",
       "      <td>non-sexist</td>\n",
       "      <td>es</td>\n",
       "      <td>metwo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58762 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               original_id                                               text  \\\n",
       "0                        0              no sab√≠a que \"random\" era una opci√≥n.   \n",
       "1                        1              los dos √∫ltimos deber√≠an haberse ido.   \n",
       "2                        2  \"ladyboner\" merece mucho m√°s cr√©dito que \"dude...   \n",
       "3                        3           a partir de ahora se llamar√° \"sourpuss\".   \n",
       "4                        4  tarah w sacrific√≥ a varias mujeres para ganar ...   \n",
       "...                    ...                                                ...   \n",
       "58757  1047687262455177217  yo no puedo darte luz todos los d√≠as, pero si ...   \n",
       "58758  1064482731739045888  que bien! aunque digan que las mujeres no debe...   \n",
       "58759  1040584804536856577  y misoginia las pelotas no quiero que vengas a...   \n",
       "58760  1051458429280235520  \"imaginen el tipo de sociedad mojigata y castr...   \n",
       "58761  1020717495605489673  por favor pase a la historia como una mujer qu...   \n",
       "\n",
       "       sexist        type language dataset  \n",
       "0           0  non-sexist    es-mx  callme  \n",
       "1           0  non-sexist    es-mx  callme  \n",
       "2           0  non-sexist    es-mx  callme  \n",
       "3           0  non-sexist    es-mx  callme  \n",
       "4           0  non-sexist    es-mx  callme  \n",
       "...       ...         ...      ...     ...  \n",
       "58757       0  non-sexist       es   metwo  \n",
       "58758       0  non-sexist       es   metwo  \n",
       "58759       0  non-sexist       es   metwo  \n",
       "58760       0  non-sexist       es   metwo  \n",
       "58761       0  non-sexist       es   metwo  \n",
       "\n",
       "[58762 rows x 6 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/transformed/gold_data.tsv\", sep=\"\\t\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bc5af3-fed2-4850-ac39-66fcd7625d3d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Initial Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee83fef-8abf-4c56-bb72-39b8786a75ad",
   "metadata": {},
   "source": [
    "For the initial training approach, we worked with a Spanish dataset consisting of 11,479 tweets. The tweets were labeled as either sexist or non-sexist, with a quite balanced distribution of approximately 46% and 54% respectively. In the second training approach, which involved incorporating translations, a larger dataset of 58,399 tweets was utilized. However, this dataset exhibited an imbalanced label distribution, with approximately 68.5% classified as non-sexist and 31.5% classified as sexist. To ensure a fair comparison between the two approaches, we needed to address this imbalance.\n",
    "\n",
    "We decided to adjust the positive class ratio in the translated dataset to match that of the Spanish dataset, which was 45%. To achieve this, we employed a technique called undersampling. By randomly discarding instances from the majority class (non-sexist), we reduced its percentage in the dataset, resulting in a more balanced distribution. This adjusted dataset served as the final training data for our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be22c357-9d41-44dc-a705-993b63a68b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_data_with_undersampling(df, positive_ratio) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Balances the data by performing undersampling on the majority class.\n",
    "\n",
    "    This function takes a DataFrame containing labeled data and performs undersampling\n",
    "    on the majority class to balance the distribution of positive and negative instances.\n",
    "    It ensures that the positive-to-negative ratio in the resulting dataset is not higher\n",
    "    than the specified positive ratio.\n",
    "\n",
    "    Args:\n",
    "        - df (pandas.DataFrame): The DataFrame containing the labeled data.\n",
    "        - positive_ratio (float): The desired positive-to-negative ratio after balancing.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The balanced dataset after performing undersampling.\n",
    "\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Calculate the actual positive count and ratio in the data frame\n",
    "    actual_pos_count = df.label.sum()\n",
    "    actual_pos_ratio = actual_pos_count / len(df)\n",
    "    \n",
    "    # Check if the actual positive ratio is higher than the desired positive ratio\n",
    "    _changed = False\n",
    "    if actual_pos_ratio > positive_ratio:\n",
    "        # Invert the labels if the actual positive ratio is higher\n",
    "        df.label = df.label.apply(lambda x: not x)\n",
    "        actual_pos_count = len(df) - actual_pos_count\n",
    "        actual_pos_ratio = 1 - actual_pos_ratio\n",
    "        positive_ratio = 1 - positive_ratio\n",
    "        _changed = True\n",
    "    \n",
    "    # Get all the positive instances\n",
    "    pos_instances = df.loc[df.label == 1, :]\n",
    "    \n",
    "    # Undersample the negative class\n",
    "    neg_instances_allowed = int(actual_pos_count * ((1 - positive_ratio) / positive_ratio))\n",
    "    neg_instances = df.loc[df.label == 0, :].sample(n=neg_instances_allowed)\n",
    "    \n",
    "    # Concatenate positive and negative instances to create a balanced dataset\n",
    "    balanced_data = pd.concat([pos_instances, neg_instances], axis=0)\n",
    "    \n",
    "    # Revert the label inversion if performed earlier\n",
    "    if _changed:\n",
    "        balanced_data.label = balanced_data.label.apply(lambda x: not x).astype(int)\n",
    "    \n",
    "    return balanced_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8e08ea-bd43-42ed-9736-c5530b0296fd",
   "metadata": {},
   "source": [
    "### Adapting to ü§ó Hugging Face Ecosystem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f601c01-1792-48e6-a957-d90108290fbd",
   "metadata": {},
   "source": [
    "To adapt our workflow to the ü§ó Hugging Face ecosystem, we introduced the `SexismDataset` object. This object serves as a versatile solution for efficient data preparation and tokenization in both the detection and classification tasks. It accepts a filepath or DataFrame as input, along with the task name (detection or classification) and an optional model checkpoint for tokenization.\n",
    "\n",
    "The SexismDataset object streamlines the data preparation process by loading the data and performing necessary preprocessing steps. For instance, it can rename columns to match the requirements of the task at hand (e.g., \"text\" and \"label\" for text classification fine-tuning). Additionally, it applies undersampling to balance the dataset for the detection task and performs label encoding for the classification task. The dataset is then split into training, validation, and test sets in a ratio of 75:15:10, respectively.\n",
    "\n",
    "To facilitate tokenization, the `SexismDataset` object leverages the tokenizers provided by ü§ó Hugging Face. It tokenizes the text data, taking into account a maximum sequence length of 512 tokens, and stores the tokenized representations of the dataset.\n",
    "\n",
    "By encapsulating the data preparation and tokenization processes within the `SexismDataset` object, we ensure consistency and modularity in our workflow. This approach allows us to handle the specific requirements of the detection and classification tasks while sharing common functionality. Furthermore, the object provides a convenient interface for accessing the tokenized dataset and calculating evaluation metrics for both tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26812388-008f-4191-b363-53b9131edaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer\n",
    "import evaluate\n",
    "\n",
    "from typing import List, Dict, Tuple, Union, Callable, Optional\n",
    "\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "precision_metric = evaluate.load(\"precision\")\n",
    "recall_metric = evaluate.load(\"recall\")\n",
    "\n",
    "class SexismDataset:\n",
    "    def __init__(\n",
    "            self, \n",
    "            filepath_or_df: Union[str, pd.DataFrame], \n",
    "            task_name: str, \n",
    "            model_checkpoint: Optional[str] = None, \n",
    "            seed: int = 1234, \n",
    "            max_instances: Optional[Union[int, float]] = None\n",
    "        ):\n",
    "        \"\"\"\n",
    "        Initialize the SexismDataset object.\n",
    "\n",
    "        Parameters:\n",
    "            - filepath_or_df (Union[str, pd.DataFrame]): Path to a CSV/TSV file or a pandas DataFrame containing the dataset.\n",
    "            - task_name (str): Task name, either \"detection\" or \"classification\".\n",
    "            - model_checkpoint (Optional[str]): Model checkpoint for tokenization.\n",
    "            - seed (int): Random seed for reproducibility.\n",
    "            - max_instances (Optional[Union[int, float]]): Maximum number of instances to include in the dataset.\n",
    "        \"\"\"\n",
    "        self.seed = seed\n",
    "        self.task = task_name\n",
    "        self._max_instances = max_instances\n",
    "        \n",
    "        if isinstance(filepath_or_df, str):\n",
    "            # Load dataset from a file\n",
    "            self._df = pd.read_csv(\n",
    "                filepath_or_buffer=filepath_or_df, \n",
    "                sep=\"\\t\" if filepath_or_df.endswith(\".tsv\") else \";\"\n",
    "            )\n",
    "        elif isinstance(filepath_or_df, pd.DataFrame):\n",
    "            # Use the provided DataFrame\n",
    "            self._df = filepath_or_df.copy()\n",
    "        \n",
    "        self._df.rename(\n",
    "            columns={\"sexist\" if self.task == \"detection\" else \"type\": \"label\"},\n",
    "            inplace=True\n",
    "        )\n",
    "        \n",
    "        if max_instances:\n",
    "            # Perform undersampling if max_instances is specified\n",
    "            self._df = self.sample_df(max_instances)\n",
    "        \n",
    "        self.num_labels = len(self._df.label.unique())\n",
    "        \n",
    "        self.dataset = self._prepare_dataset()\n",
    "        \n",
    "        if model_checkpoint:\n",
    "            # Tokenize the dataset if a model checkpoint is provided\n",
    "            print(\"Tokenizing dataset...\")\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
    "            self.tokenized = self.dataset.map(self._tokenize, batched=True)\n",
    "          \n",
    "    def _make_dataset_from_pandas(self, data: Union[pd.DataFrame,dict]):\n",
    "        \"\"\"\n",
    "        Convert a pandas DataFrame or dictionary of DataFrames to a Hugging Face Dataset object.\n",
    "\n",
    "        Parameters:\n",
    "            - data (Union[pd.DataFrame, dict]): Input data to convert.\n",
    "\n",
    "        Returns:\n",
    "            Dataset: Hugging Face Dataset object.\n",
    "        \"\"\"\n",
    "        if isinstance(data, pd.DataFrame):\n",
    "            # Convert single DataFrame\n",
    "            return Dataset.from_pandas(data)\n",
    "        elif isinstance(data, dict):\n",
    "            # Convert dictionary of DataFrames\n",
    "            ds_dict = DatasetDict()\n",
    "            for split, df in data.items():\n",
    "                ds_dict[split] = Dataset.from_pandas(df)\n",
    "            return ds_dict \n",
    "\n",
    "    def _prepare_dataset(self):\n",
    "        \"\"\"\n",
    "        Prepare the dataset for training.\n",
    "\n",
    "        Returns:\n",
    "            Dataset: Prepared dataset.\n",
    "        \"\"\"\n",
    "        data = self._df.loc[:, [\"text\", \"label\"]]\n",
    "        \n",
    "        if self.task == \"detection\":\n",
    "            # Perform label balancing (undersampling) for detection task\n",
    "            data = balance_data_with_undersampling(data, positive_ratio=0.45)\n",
    "\n",
    "        elif self.task == \"classification\":\n",
    "            # Perform label encoding for classification task\n",
    "            self.le = LabelEncoder()\n",
    "            data.label = self.le.fit_transform(data.label.to_list())\n",
    "\n",
    "        # Split the data into training, validation, and test sets\n",
    "        train_data, eval_data = train_test_split(data, \n",
    "                                                 test_size=0.25, \n",
    "                                                 stratify=data.label, \n",
    "                                                 shuffle=True, \n",
    "                                                 random_state=self.seed)\n",
    "        \n",
    "        # Split the evaluation data into validation and test sets\n",
    "        val_data, test_data = train_test_split(eval_data, \n",
    "                                               test_size=0.1/0.25, \n",
    "                                               stratify=eval_data.label, \n",
    "                                               random_state=self.seed)\n",
    "        \n",
    "        dfs = {\"train\": train_data, \"validation\": val_data, \"test\": test_data}\n",
    "        ds = self._make_dataset_from_pandas(dfs).select_columns([\"text\", \"label\"])\n",
    "        if \"__index_level_0__\" in ds.column_names:\n",
    "            ds.remove_columns(\"__index_level_0__\")\n",
    "        return ds\n",
    "\n",
    "    def _tokenize(self, examples):\n",
    "        \"\"\"\n",
    "        Tokenize input examples using the specified tokenizer.\n",
    "\n",
    "        Parameters:\n",
    "            - examples: Input examples to be tokenized.\n",
    "\n",
    "        Returns:\n",
    "            Dict: Tokenized examples.\n",
    "        \"\"\"\n",
    "        return self.tokenizer(examples[\"text\"], \n",
    "                              padding='max_length', \n",
    "                              max_length = 512, \n",
    "                              truncation = True)\n",
    "    \n",
    "    def sample_df(self, n_or_perc): \n",
    "        \"\"\"\n",
    "        Sample a fraction or a specific number of instances from the dataset.\n",
    "\n",
    "        Parameters:\n",
    "            - n_or_perc: Number of instances or percentage to sample.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Sampled dataset.\n",
    "        \"\"\"\n",
    "        if n_or_perc < 0:\n",
    "            raise ValueError(\"'n_or_perc' must be positive\")\n",
    "        if n_or_perc > 1: \n",
    "            n_or_perc /= len(self._df)\n",
    "        data, _ =  train_test_split(self._df, \n",
    "                                    train_size=n_or_perc,\n",
    "                                    stratify=self._df.label,\n",
    "                                    shuffle=True, \n",
    "                                    random_state=self.seed)\n",
    "        return data\n",
    "        \n",
    "    def build_compute_metrics(self):\n",
    "        \"\"\"\n",
    "        Build a compute_metrics function for evaluating the model.\n",
    "\n",
    "        Returns:\n",
    "            function: Compute metrics function.\n",
    "        \"\"\"\n",
    "        def compute_metrics(eval_pred):\n",
    "            logits, labels = eval_pred\n",
    "            predictions = np.argmax(logits, axis=1)\n",
    "            compute_kwargs = {\n",
    "                \"predictions\": predictions,\n",
    "                \"references\": labels\n",
    "            }\n",
    "            average = \"binary\" if self.task == \"detection\" else \"macro\"\n",
    "            return {\n",
    "                **accuracy_metric.compute(**compute_kwargs),\n",
    "                **f1_metric.compute(**compute_kwargs, average=average),\n",
    "                **precision_metric.compute(**compute_kwargs, average=average),\n",
    "                **recall_metric.compute(**compute_kwargs, average=average)\n",
    "            }\n",
    "        return compute_metrics\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Get the dataset or tokenized examples.\n",
    "\n",
    "        Parameters:\n",
    "            - key: Key to access dataset or tokenized examples.\n",
    "\n",
    "        Returns:\n",
    "            Dataset or Tokenized: Dataset or tokenized examples.\n",
    "        \"\"\"\n",
    "        if key == \"dataset\":\n",
    "            return self.dataset\n",
    "        elif key == \"tokenized\":\n",
    "            return self.tokenized\n",
    "        else:\n",
    "            raise KeyError(f\"{key} not supported. Must be 'dataset' or 'tokenized'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a21f33-b5e9-4e6c-9cc0-9168e4b3517b",
   "metadata": {},
   "source": [
    "With the data prepared and tokenized using the `SexismDataset` object, we are almost ready to proceed with training and evaluating our models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330492e4-f111-4de6-93de-22c0a826f29f",
   "metadata": {},
   "source": [
    "## The Base Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15140985-6026-4f90-bad6-237e45a29b61",
   "metadata": {},
   "source": [
    "For our project, we selected [\"roberta-base-bne\"](https://huggingface.co/PlanTL-GOB-ES/roberta-base-bne) as our base model. This is part of the [Spanish Government's Language Technology Plan](https://plantl.mineco.gob.es/tecnologias-lenguaje/Paginas/tecnologias-lenguaje.aspx) and is specifically designed for the Spanish language. It is built upon the RoBERTa base model ([ref.](https://arxiv.org/abs/1907.11692)), a highly acclaimed transformer-based masked language model.\n",
    "\n",
    "The \"roberta-base-bne\" model has undergone extensive pre-training using a vast Spanish corpus, which comprises 570GB of clean and deduplicated text, was meticulously compiled from web crawlings conducted by the National Library of Spain ([Biblioteca Nacional de Espa√±a](https://www.bne.es/en/Inicio/index.html)) between 2009 and 2019. This rich and diverse dataset provides a solid foundation for the model's understanding of the Spanish language .\n",
    "\n",
    "We specifically chose the \"roberta-base-bne\" model due to its exceptional performance in various Spanish NLP tasks. RoBERTa-based models have consistently achieved state-of-the-art results, demonstrating their effectiveness in capturing the intricacies and nuances of the Spanish language ([ref.](http://journal.sepln.org/sepln/ojs/ojs/index.php/pln/article/view/6405/3820)).\n",
    "\n",
    "To acquire and fine-tune our models, we relied on the powerful [ü§ó HuggingFace](https://huggingface.co/) Transformers library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7c29c0-5bc4-4cc2-bad0-071acce7b09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CHECKPOINT = \"PlanTL-GOB-ES/roberta-base-bne\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bfccd5-be66-4b8a-9d47-506e30998d81",
   "metadata": {},
   "source": [
    "With the data prepared and tokenized using the `SexismDataset` object, we are now equipped with the necessary components to proceed with the fine-tuning, training, and evaluation of our models. The \"roberta-base-bne\" model, with its deep understanding of the Spanish language, will serve as the foundation for our journey into detecting and classifying online sexism in Spanish tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce10961-34cc-4504-be2f-1da26ecf7a49",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Josefina - Sexism Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3c64dd-064f-4141-8b82-8d06d9f1f3bb",
   "metadata": {},
   "source": [
    "Now, let's delve into the training stage of the notebook, where we develop the models. Our primary objective is sexism detection, and to accomplish this, we introduce Josefina, a robust NLP model meticulously crafted to combat sexism in text. Harnessing the power of advanced language processing techniques, Josefina excels at identifying and addressing gender bias, actively advocating for fairness and inclusivity. Through its meticulous analysis of language patterns, Josefina skillfully uncovers even the most nuanced instances of sexism, contributing significantly to the creation of a more respectful and equitable online environment.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c26e55d-210e-41b2-ae0d-b2b2ed557174",
   "metadata": {},
   "source": [
    "### Training with Original Spanish data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5f5976-cbb1-44c5-855d-336e4302bf4a",
   "metadata": {},
   "source": [
    "In this subsection, we focus on training our model using the original Spanish dataset. The dataset, specifically curated for this project, consists of tweets written in Spanish. We begin by filtering the data to include only the Spanish language using the 'language' attribute. This refined dataset is then passed into the SexismDataset object, specifically configured for the 'detection' task and using the designated model checkpoint. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "485b9748-005e-4148-b59a-989b03483aab",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "18624acd4143497dbc6ef9213568189a",
      "6f4700e1dd7f4cdd84b9455361b28ed3",
      "e1e6af007fcc42ebbbd8bc8dd3b52010",
      "c86282a8bc394ded8681e370fafa7699",
      "6b550f8fb327413ab14bb52621598aab",
      "8057885aa2eb41549f7e8844275bf655",
      "77b4cf2e36ec40ecbaadfd97c8349f03",
      "343c0b771f1240a689937d0abc2f6821",
      "9050b2e64ecd4b69bfc6f06a831cc045",
      "5382c8083fd647d2a98c0c959feb6314",
      "085df2b21ef44ddabefc98a6a305e143",
      "6b268d0f4e7348f8886fbe771473e9e8",
      "18dc5fe1794b42d5ab64e46f3599aba1",
      "c65e300542684937a8b23d27e2662f61",
      "5e201e898553495eb91c7ef3cf6d4e75",
      "5c87354b2dfe42df9d39e3ca83e20b26",
      "bddb40cc53234a48ae6fdb7787b5544e",
      "56772115fd9f4ca7a0fea412be087195",
      "d15073b3b6d84bbaa1f76db8cb1ccbc4",
      "e07933023abe4c7fb6c4a08c8545d8a9",
      "3dba52a670d44e9fb7745b09e99cd147",
      "25b57d2d6a47411c8e6ba834579c53be",
      "0f8d5d21494b4349b75c03dfa6fcdd09",
      "7a82b28aafc8402b9ce91f9d8ad39e52",
      "26693ed0899c431ca1f8f14967eae6a3",
      "b7781be2a5614ff68fb15df64fb02f04",
      "7e4e528fff7e408f8c56e0706bea6db0",
      "a92f397df1684b35bb4f14207a516bbb",
      "9fb8211fc4214cd597c55687ce836814",
      "824513b9a7f44b41bd67ed588cf85e8d",
      "8787d0b2b3894df28d9c80a5aa5414d9",
      "d519943a3be84223811576cebea11791",
      "cc29fcb6c154478f9bf4f526c053391c"
     ]
    },
    "id": "CfAMJ-cPpTDc",
    "outputId": "32b9ca46-2fba-4dfc-e295-496497c79e42"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18624acd4143497dbc6ef9213568189a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8409 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b268d0f4e7348f8886fbe771473e9e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1681 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f8d5d21494b4349b75c03dfa6fcdd09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1122 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_es = data.query(\"language == 'es'\")\n",
    "sexism_data_es = SexismDataset(data_es, \n",
    "                               task_name=\"detection\", \n",
    "                               model_checkpoint=MODEL_CHECKPOINT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea8b409-dbfb-4ca8-9e53-69138e4e2a3d",
   "metadata": {},
   "source": [
    "To further advance in our model development, we have implemented a crucial function called `train_transformer`. This function serves as the cornerstone for training our transformer-based models using tokenized datasets. By providing the necessary inputs, such as the fancy name for the training run, the tokenized dataset, the model name or path, the number of labels for the classification task, the tokenizer, and a function to compute evaluation metrics, we can efficiently train our models. Moreover, this function offers the flexibility to customize hyperparameters and choose whether to push the trained model to the Hugging Face model hub and evaluate its performance on the validation and test datasets. This powerful function streamlines the training process and enables us to iterate and refine our models effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22aab4c9-547e-4e6d-8bf7-30a6589da5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ( \n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification, \n",
    "    Trainer, \n",
    "    TrainingArguments\n",
    ")\n",
    "#from api_setup import wandb_setup, huggingface_setup\n",
    "\n",
    "def train_transformer(\n",
    "    \n",
    "    fancy_name: str,\n",
    "    tokenized_dataset: Dataset,\n",
    "    model_name: str,\n",
    "    num_labels: int,\n",
    "    tokenizer: AutoTokenizer,\n",
    "    compute_metrics: Callable,\n",
    "    hyper_params: dict = {},\n",
    "    push_to_hub: bool = False,\n",
    "    evaluate: bool = True\n",
    "    \n",
    ") -> Trainer:\n",
    "    \"\"\"\n",
    "    Trains a transformer-based model using the provided tokenized dataset and hyperparameters.\n",
    "\n",
    "    Args:\n",
    "        - fancy_name (str): A fancy name to identify the training run.\n",
    "        - tokenized_dataset (datasets.Dataset): The tokenized dataset for training, validation, and testing.\n",
    "        - model_name (str): The name or path of the pre-trained transformer model.\n",
    "        - num_labels: The number of labels/classes for the classification task.\n",
    "        - tokenizer (transformers.AutoTokenizer): The tokenizer for tokenizing the input sequences.\n",
    "        - compute_metrics (Callable): A function to compute evaluation metrics.\n",
    "        - hyper_params (dict, optional): Specific hyperparameters for training the model. Defaults to {}.\n",
    "        - push_to_hub (bool, optional): Whether to push the trained model to the Hugging Face model hub. Defaults to False.\n",
    "        - evaluate (bool, optional): Whether to evaluate the trained model on the validation and test datasets. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        Trainer: The trainer object used for training the model.\n",
    "    \"\"\"\n",
    "    \n",
    "    #if push_to_hub:\n",
    "    #    huggingface_setup()\n",
    "        \n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name, num_labels=num_labels\n",
    "    )\n",
    "    \n",
    "    batch_size = hyper_params.get(\"batch_size\", 8)\n",
    "    args = TrainingArguments(\n",
    "        output_dir=fancy_name,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        learning_rate=hyper_params.get(\"lr\", 1.93009e-05),\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        num_train_epochs=hyper_params.get(\"epochs\", 4),\n",
    "        warmup_steps=hyper_params.get(\"warmup_steps\", 0),\n",
    "        weight_decay=hyper_params.get(\"weight_decay\", 0.01),\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        push_to_hub=push_to_hub,\n",
    "        max_steps=-1,\n",
    "        report_to=None\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model,\n",
    "        args,\n",
    "        train_dataset=tokenized_dataset[\"train\"],\n",
    "        eval_dataset=tokenized_dataset[\"validation\"],\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    \n",
    "    if evaluate:\n",
    "        print(\"\\nFinal model evaluation:\")\n",
    "        trainer.evaluate()\n",
    "        print(\"\\nResults over test data:\")\n",
    "        preds = trainer.predict(tokenized_dataset[\"test\"])\n",
    "        print(preds.metrics)\n",
    "    \n",
    "    return trainer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8e0509-11c7-4ca6-8e5e-445f65b2d86e",
   "metadata": {},
   "source": [
    "With the train_transformer function implemented, we proceeded to train our first approach for the Sexism Detection task using the original Spanish dataset. The function call was made, specifying the tokenized dataset, model name, number of labels, tokenizer, and evaluation metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fe1ba9b-9156-44ff-9583-94001276c386",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 463
    },
    "id": "656b20bd-1c19-41ad-b135-e39cd81f8d7b",
    "outputId": "5526b8af-7d51-4081-e6c4-d03d332ae244"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at PlanTL-GOB-ES/roberta-base-bne were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at PlanTL-GOB-ES/roberta-base-bne and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3364' max='3364' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3364/3364 51:20, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.542400</td>\n",
       "      <td>0.473272</td>\n",
       "      <td>0.787032</td>\n",
       "      <td>0.781707</td>\n",
       "      <td>0.725113</td>\n",
       "      <td>0.847884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.331000</td>\n",
       "      <td>0.627118</td>\n",
       "      <td>0.790601</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.790230</td>\n",
       "      <td>0.727513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.122700</td>\n",
       "      <td>0.973361</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.752183</td>\n",
       "      <td>0.763984</td>\n",
       "      <td>0.740741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.044900</td>\n",
       "      <td>1.147916</td>\n",
       "      <td>0.782867</td>\n",
       "      <td>0.751869</td>\n",
       "      <td>0.773427</td>\n",
       "      <td>0.731481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final model evaluation:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.473271906375885, 'eval_accuracy': 0.7870315288518739, 'eval_f1': 0.7817073170731708, 'eval_precision': 0.7251131221719457, 'eval_recall': 0.8478835978835979, 'eval_runtime': 50.3726, 'eval_samples_per_second': 33.371, 'eval_steps_per_second': 3.355, 'epoch': 4.0}\n",
      "\n",
      "Results over test data:\n",
      "{'test_loss': 0.47722914814949036, 'test_accuracy': 0.7816399286987522, 'test_f1': 0.7758462946020128, 'test_precision': 0.7210884353741497, 'test_recall': 0.8396039603960396, 'test_runtime': 32.7923, 'test_samples_per_second': 34.215, 'test_steps_per_second': 3.446}\n"
     ]
    }
   ],
   "source": [
    "detector_trainer_es = train_transformer(fancy_name=\"unicc-josefina-sexism-detection-v0\", \n",
    "                                        tokenized_dataset=sexism_data_es.tokenized, \n",
    "                                        model_name=MODEL_CHECKPOINT,\n",
    "                                        num_labels=sexism_data_es.num_labels,\n",
    "                                        tokenizer=sexism_data_es.tokenizer,\n",
    "                                        compute_metrics=sexism_data_es.build_compute_metrics()\n",
    "                                        evaluate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a36ccd-905e-4e87-b51a-ede6535984a0",
   "metadata": {},
   "source": [
    "The training process for the Sexism Detection model on the original Spanish dataset showed promising results. The model achieved an accuracy of approximately 78.7% and an F1 score of around 0.78. These metrics indicate a good performance in identifying instances of sexism. The evaluation on the test data also yielded similar results, with an accuracy of 78.2% and an F1 score of 0.77. These outcomes demonstrate the model's effectiveness in detecting sexism in the Spanish language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397091e8-317d-4783-bdbd-6dff0036ca74",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector_trainer_es.save_model(\"../src3/detector/josefina-sexism-detection-v0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8f2ed9-54a1-48a2-8a33-ae0bb3ad718a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Training with Also Translated data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024b6c2a-f9f4-4aef-bcde-726776e9dc95",
   "metadata": {},
   "source": [
    "Continuing with the training process, we now proceed with the second approach, which involves using translated data. The dataset consists of instances translatef from English to Mexican Spanish. We initialize the SexismDataset object with this translated data and then call the train_transformer function to train the model. This allows us to leverage the power of pre-trained language models and fine-tune them on the translated dataset. The evaluation results will shed light on the model's performance in detecting sexism in various languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8a271e1-6952-4779-92f1-a3606aaabb43",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "2ba52692f5f34689b5752732cb9a4bd1",
      "6009c6089970483096c713a4944a2617",
      "11a53370efd642458088e54215723771",
      "dd0489e64715459eb7e554e08d5a0a26",
      "96c99a0a3f0a4a17971ebadbac210ed4",
      "a50a3849bf09420ea858ba80fa2f0d0d",
      "bce9238e06d24e588e54854ac269ddb0",
      "bcbd77a227fb444089fdf4c6aed36881",
      "ec11936da3404c0ba9d7a699c7f3d393",
      "de08c14d135945988ee9a791539c178e",
      "fe3c906f3169431a9886b935cc1becf3",
      "f378bb34e91047f98447bfae8141fadd",
      "4e865dbc4956479b985439c7360530dd",
      "ce88eb1c82b544ac920c601bcc6b34ef",
      "1a095905badc4ae78015b6651a5be770",
      "4912c47599974439a475a45088ba373d",
      "27ec58ecbbf94c26a64b302cd911cc32",
      "b68a5ad252ba42e99f37830319e0af77",
      "76f437c57ae34b699cc15c6808410941",
      "f20d3e2384ab485799f711a48f4f4850",
      "0325210d66e34087802e0440e764e1d6",
      "dc966cd650bc42afa85e84301e712a7c",
      "c2d2ade1cfae4b509bbff8786a7da3ed",
      "92b757c616634c0382208b0f22f48a14",
      "485c5db609bc48288a8b7bc0f4c05470",
      "d56f35461dae4580a1c51eb4f00696c9",
      "736adb05fdcb40a78f645d56daeae9ed",
      "3629f926200341c8ba8c7ec689c9c2aa",
      "812bf7d514344808bd078519c414a7e5",
      "bd9e51b234c042f49acf68e9f8ce6b49",
      "08aae65d453c4855abb3d6777c2b69bf",
      "b3612b313a5b4db3a10ecac1fc36ac12",
      "e6387c038dec4193a2a69381e42ed510"
     ]
    },
    "id": "GtL9sC10V1p0",
    "outputId": "73deda40-40cd-492b-b417-76658f8ac436"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ba52692f5f34689b5752732cb9a4bd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/30668 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f378bb34e91047f98447bfae8141fadd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6133 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2d2ade1cfae4b509bbff8786a7da3ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4090 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_data = data.query(\"language != 'en'\")\n",
    "sexism_data = SexismDataset(full_data, \n",
    "                            task_name=\"detection\", \n",
    "                            model_checkpoint=MODEL_CHECKPOINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c42f4406-75fd-4b06-8649-4fff029fd464",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "id": "ffea13a3-94a1-4955-9929-65448d35aaad",
    "outputId": "bed92d48-d350-4dac-a220-ee7d91aebc45"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at PlanTL-GOB-ES/roberta-base-bne were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at PlanTL-GOB-ES/roberta-base-bne and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12268' max='12268' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12268/12268 3:05:13, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.455200</td>\n",
       "      <td>0.460996</td>\n",
       "      <td>0.793739</td>\n",
       "      <td>0.776225</td>\n",
       "      <td>0.758382</td>\n",
       "      <td>0.794928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.329300</td>\n",
       "      <td>0.540328</td>\n",
       "      <td>0.800587</td>\n",
       "      <td>0.790115</td>\n",
       "      <td>0.750571</td>\n",
       "      <td>0.834058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.150400</td>\n",
       "      <td>0.919486</td>\n",
       "      <td>0.804989</td>\n",
       "      <td>0.783019</td>\n",
       "      <td>0.784157</td>\n",
       "      <td>0.781884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.041800</td>\n",
       "      <td>1.243308</td>\n",
       "      <td>0.793739</td>\n",
       "      <td>0.777014</td>\n",
       "      <td>0.756608</td>\n",
       "      <td>0.798551</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final model evaluation:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5403280854225159, 'eval_accuracy': 0.8005869884232839, 'eval_f1': 0.790114981980436, 'eval_precision': 0.7505705901532442, 'eval_recall': 0.8340579710144927, 'eval_runtime': 180.4854, 'eval_samples_per_second': 33.981, 'eval_steps_per_second': 3.402, 'epoch': 4.0}\n",
      "\n",
      "Results over test data:\n",
      "{'test_loss': 0.5582737922668457, 'test_accuracy': 0.7973105134474328, 'test_f1': 0.7843953185955788, 'test_precision': 0.7521197007481297, 'test_recall': 0.8195652173913044, 'test_runtime': 120.3954, 'test_samples_per_second': 33.971, 'test_steps_per_second': 3.397}\n"
     ]
    }
   ],
   "source": [
    "detector_trainer = train_transformer(fancy_name=\"unicc-josefina-sexism-detection\", \n",
    "                                     tokenized_dataset=sexism_data.tokenized, \n",
    "                                     model_name=MODEL_CHECKPOINT,\n",
    "                                     num_labels=sexism_data.num_labels,\n",
    "                                     tokenizer=sexism_data.tokenizer,\n",
    "                                     compute_metrics=sexism_data.build_compute_metrics()\n",
    "                                     evaluate=True,\n",
    "                                     hyper_params={\"batch\":10})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215ae82e-36f3-42a1-8b84-508f413a86c7",
   "metadata": {},
   "source": [
    "In comparing the model trained with translated data to the model trained with only original Spanish data, we observed notable improvements in various performance metrics. The F1 score of the translated data model reached 0.790, surpassing the F1 score of 0.751 achieved by the original Spanish model. This enhancement signifies the model's increased ability to effectively capture instances of sexism when trained on a more diverse dataset that includes translated instances. Moreover, the precision score of the translated data model improved to 0.751, indicating a higher level of accuracy in identifying positive instances compared to the original Spanish model. The recall score also increased to 0.819, indicating an enhanced capability to capture a greater proportion of actual positive instances. These results highlight the value of incorporating translated data to improve the overall performance and robustness of the sexism detection model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e36c79-fc0e-4229-8fa1-baf8f4b64c8e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Hyperparameter Search with Population-Based Training\n",
    "\n",
    "In this subsection, we perform a hyperparameter search using a technique called Population-Based Training (PBT). The goal is to find optimal hyperparameters for training a transformer model. The hp_tune_transformer function is used for this purpose, and it leverages the Ray Tune library to perform the hyperparameter search.\n",
    "\n",
    "> ##### Population-Based Training (PBT)\n",
    ">PBT is an optimization technique that combines population-based optimization with asynchronous hyperparameter tuning. It starts by sampling a population of hyperparameter configurations, and each configuration is trained and evaluated on a subset of the data. Based on their performance, the best configurations are identified and their hyperparameters are mutated and re-evaluated in subsequent iterations. This process of mutation and evaluation helps refine the hyperparameters over time, leading to improved performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e7f3a5-2e1d-4e3e-a4b9-197f1a5fd41c",
   "metadata": {},
   "source": [
    "The `hp_tune_transformer` function is a versatile tool for hyperparameter search using the Population-Based Training (PBT) strategy. It enables efficient exploration of the hyperparameter space to discover the optimal configuration for training a transformer model. This function leverages the Ray Tune library to perform iterative training and evaluation with various hyperparameter configurations, iteratively refining the parameters to improve model performance. With inputs such as the model name, tokenized dataset, tokenizer, and evaluation metrics, it supports reporting, logging, and saving the best hyperparameters and model. By using hp_tune_transformer, you can automate hyperparameter search and effectively enhance the performance of your transformer models. Is allows reporting to Weigths & Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bcd40168-1554-44ca-bede-38a3a1845bd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import PopulationBasedTraining\n",
    "\n",
    "#from api_setup import wandb_setup\n",
    "#from misc import save_json\n",
    "\n",
    "def get_setup_keys(*keys):\n",
    "    aux, _suggest = {}, False\n",
    "    for key in keys:\n",
    "        value = os.getenv(key)\n",
    "        if value is None:\n",
    "            value = input(f\"Enter your `{key}`: \")\n",
    "            _suggest = True\n",
    "        aux[key] = value\n",
    "    if _suggest:\n",
    "        print(\"\\nConsider setting keys in system environ to not\" \\\n",
    "              \"\\nenter them each time setting up is required.\\n\")\n",
    "    return aux\n",
    "\n",
    "def wandb_setup(project_name):\n",
    "    import wandb\n",
    "    #wandb.login()\n",
    "    key = get_setup_keys(\"WANDB_API_KEY\")\n",
    "    os.environ[\"WANDB_API_KEY\"] = key[\"WANDB_API_KEY\"]\n",
    "    # set the wandb project where this run will be logged\n",
    "    os.environ[\"WANDB_PROJECT\"] = project_name\n",
    "    # save your trained model checkpoint to wandb\n",
    "    os.environ[\"WANDB_LOG_MODEL\"]=\"true\"\n",
    "    # turn off watch to log faster\n",
    "    os.environ[\"WANDB_WATCH\"] = \"false\"\n",
    "    wandb.init()\n",
    "    \n",
    "def save_json(dict_, path):\n",
    "    with open(path, mode='w+', encoding='utf-8') as f:\n",
    "        json.dump(dict_, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "def hp_tune_transformer(\n",
    "        fancy_name: str,\n",
    "        model_name: str,\n",
    "        tokenized_dataset: Dataset,\n",
    "        num_labels: int,\n",
    "        tokenizer: AutoTokenizer,\n",
    "        compute_metrics: Callable, \n",
    "        num_samples: int = 8, \n",
    "        cpus_per_trial: int = 1, \n",
    "        gpus_per_trial: int = 0, \n",
    "        report_to: Optional[str] = None,\n",
    "        save_best_model: bool = False,\n",
    "        smoke_test: bool = False\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Perform hyperparameter search using Population-Based Training (PBT) to find optimal hyperparameters\n",
    "    for training a transformer model.\n",
    "\n",
    "    Args:\n",
    "        - fancy_name (str): Name for the fancy experiment.\n",
    "        - model_name (str): Name or path of the pre-trained transformer model.\n",
    "        - tokenized_dataset (Dataset): Tokenized dataset containing train, validation, and test splits.\n",
    "        - num_labels (int): Number of labels/classes in the dataset.\n",
    "        - tokenizer (AutoTokenizer): Tokenizer for the transformer model.\n",
    "        - compute_metrics (Callable): Function to compute evaluation metrics.\n",
    "        - num_samples (int, optional): Number of hyperparameter samples to try. Defaults to 8.\n",
    "        - cpus_per_trial (int, optional): Number of CPUs to allocate per trial. Defaults to 1.\n",
    "        - gpus_per_trial (int, optional): Number of GPUs to allocate per trial. Defaults to 0.\n",
    "        - report_to (Optional[str], optional): Reporting destination (e.g., 'wandb' for Weights & Biases).\n",
    "                                               Defaults to None.\n",
    "        - save_best_model (bool, optional): Whether to save the best model. Defaults to False.\n",
    "        - smoke_test (bool, optional): Whether to perform a smoke test. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        BestRun: The best hyperparameter run.\n",
    "    \"\"\"\n",
    "    print(\"\\nSTARTING HYPER-PARAMETER SEARCH\")\n",
    "    print(\"\\nDownloading and caching pre-trained model\")\n",
    "    model_config = AutoConfig.from_pretrained(\n",
    "        model_name, num_labels=num_labels\n",
    "    )\n",
    "    \n",
    "    # Triggers model download to cache\n",
    "    AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name, config=model_config,\n",
    "    )\n",
    "\n",
    "    def get_model():\n",
    "        return AutoModelForSequenceClassification.from_pretrained(\n",
    "            model_name, config=model_config,\n",
    "        )\n",
    "\n",
    "    # Sets training and hyperparameter search configuration\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=fancy_name,\n",
    "        learning_rate=1e-5,  # config\n",
    "        do_train=True,\n",
    "        do_eval=True,\n",
    "        no_cuda=gpus_per_trial <= 0,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        num_train_epochs=2,  # config\n",
    "        max_steps=-1,\n",
    "        per_device_train_batch_size=16,  # config\n",
    "        per_device_eval_batch_size=16,  # config\n",
    "        warmup_steps=0,  # config\n",
    "        weight_decay=0.01,  # config\n",
    "        logging_dir=\"./logs\",\n",
    "        skip_memory_metrics=True,\n",
    "        report_to=report_to\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model_init=get_model,\n",
    "        args=training_args,\n",
    "        tokenizer=tokenizer,\n",
    "        train_dataset=tokenized_dataset[\"train\"],\n",
    "        eval_dataset=tokenized_dataset[\"validation\"],\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    tune_config = {\n",
    "        \"per_device_train_batch_size\": tune.choice([8, 16, 32, 64]),\n",
    "        \"per_device_eval_batch_size\": tune.choice([8, 16, 32, 64]),\n",
    "        \"num_train_epochs\": tune.choice([2, 3, 4, 5]),\n",
    "        \"max_steps\": 1 if smoke_test else -1,  # Used for smoke test.\n",
    "    }\n",
    "\n",
    "    scheduler = PopulationBasedTraining(\n",
    "        time_attr=\"training_iteration\",\n",
    "        metric=\"eval_f1\",\n",
    "        mode=\"max\",\n",
    "        perturbation_interval=1,\n",
    "        hyperparam_mutations={\n",
    "            \"learning_rate\": tune.uniform(1e-5, 1e-6),\n",
    "            \"weight_decay\": tune.uniform(0.0, 0.5),\n",
    "            \"warmup_steps\": tune.randint(0, 500),\n",
    "            \"per_device_train_batch_size\":  tune.choice([8, 16, 32, 64]),\n",
    "        },\n",
    "    )\n",
    "\n",
    "    reporter = CLIReporter(\n",
    "        parameter_columns={\n",
    "            \"weight_decay\": \"w_decay\",\n",
    "            \"warmup_steps\": \"warmup_steps\",\n",
    "            \"learning_rate\": \"lr\",\n",
    "            \"per_device_train_batch_size\": \"train_bs/gpu\",\n",
    "            \"num_train_epochs\": \"num_epochs\",\n",
    "        },\n",
    "        metric_columns=[\n",
    "            \"epoch\", \"training_iteration\", \"eval_loss\", \"eval_accuracy\", \n",
    "            \"eval_f1\", \"eval_precision\", \"eval_recall\"\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    ray.shutdown()\n",
    "    ray.init(log_to_driver=True, ignore_reinit_error=True)\n",
    "\n",
    "    if report_to == \"wandb\":\n",
    "        wandb_setup(project_name=fancy_name)\n",
    "\n",
    "    best_run = trainer.hyperparameter_search(\n",
    "        hp_space=lambda _: tune_config,\n",
    "        backend=\"ray\",\n",
    "        n_trials=num_samples,\n",
    "        resources_per_trial={\"cpu\": cpus_per_trial, \"gpu\": gpus_per_trial},\n",
    "        scheduler=scheduler,\n",
    "        keep_checkpoints_num=1,\n",
    "        checkpoint_score_attr=\"training_iteration\",\n",
    "        stop={\"training_iteration\": 1} if smoke_test else None,\n",
    "        progress_reporter=reporter,\n",
    "        local_dir=\"ray_results/\",\n",
    "        name=fancy_name + \"-tune_transformer_pbt\",\n",
    "        log_to_file=not(bool(report_to)),\n",
    "    )\n",
    "    \n",
    "    print(\"\\nFinal model evaluation:\")\n",
    "    best_run.evaluate()\n",
    "    print(\"\\nResults over test data:\")\n",
    "    preds = best_run.predict(tokenized_dataset[\"test\"])\n",
    "    print(preds.metrics)\n",
    "    \n",
    "    print(\"\\nSaving results...\")\n",
    "    save_json(best_run.hyperparameters, \n",
    "              path=fancy_name + \"-best_hyperparameters.json\")\n",
    "    \n",
    "    if save_best_model: \n",
    "        best_run.save_model(fancy_name + \"-model\")\n",
    "    \n",
    "    return best_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e632e2f-e26e-4f9b-b704-938822c5ba14",
   "metadata": {},
   "outputs": [],
   "source": [
    "sexism_data_sample = SexismDataset(full_data, \n",
    "                                   task_name=\"detection\", \n",
    "                                   model_checkpoint=MODEL_CHECKPOINT,\n",
    "                                   max_instances=10000)\n",
    "\n",
    "fancy_name = \"\"\n",
    "best_run = hp_tune_transformer(fancy_name=fancy_name,\n",
    "                               model_name=MODEL_CHECKPOINT,\n",
    "                               tokenized_dataset=sexism_data_sample.tokenized,\n",
    "                               num_labels=sexism_data_sample.num_labels,\n",
    "                               tokenizer=sexism_data_sample.tokenizer,\n",
    "                               compute_metrics=sexism_data_sample.build_compute_metrics(),\n",
    "                               num_samples=8, \n",
    "                               cpus_per_trial=1, \n",
    "                               gpus_per_trial=2,\n",
    "                               report_to=\"wandb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915a5609-37f4-46b0-925b-0c92110e60b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, v in best_run.hyperparameters.items():\n",
    "    setattr(detector_trainer.args, n, v)\n",
    "\n",
    "detector_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfab1a99-dce4-4460-96f6-24c5f76a485f",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector_trainer.save_model(\"../src3/detector/josefina-sexism-detection-vf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ef11c6-f1da-4d69-8128-b224c849b5f9",
   "metadata": {},
   "source": [
    "### Optimal Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9a90f49d-c645-4c38-9d24-cb0e06328349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [3,2,1]\n",
    "a.sort(key=lambda x: x)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd620fe-4a69-4699-b156-e503d1f6d4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_from_transformer(\n",
    "        dataset: Dataset, \n",
    "        checkpoint_or_path: str,\n",
    "        mode: str = \"label\", \n",
    "        local_files_only: bool = False,\n",
    "        tokenizer_kwargs: dict = {}\n",
    ") -> np.array:\n",
    "    \"\"\"\n",
    "    Performs inference using a pre-trained transformer model on a given dataset.\n",
    "\n",
    "    Args:\n",
    "        - dataset (Dataset): The dataset to perform inference on. Must contain a \"text\" column.\n",
    "        - checkpoint_or_path (str): The checkpoint or path to the pre-trained model.\n",
    "        - mode (str, optional): The mode for prediction. Possible values are 'label' or 'proba'.\n",
    "                                'label' returns the predicted label for each sample.\n",
    "                                'proba' returns the predicted probabilities for each class.\n",
    "                                 Defaults to 'label'.\n",
    "        - local_files_only (bool, optional): Whether to only use local files when loading the model.\n",
    "                                             Defaults to False.\n",
    "        - tokenizer_kwargs (dict, optional): Additional keyword arguments to be passed to the tokenizer.\n",
    "                                             Defaults to an empty dictionary.\n",
    "\n",
    "    Returns:\n",
    "        numpy.array: An array of predicted labels or probabilities.\n",
    "\n",
    "    \"\"\"\n",
    "    # Load the tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        checkpoint_or_path, local_files_only=local_files_only\n",
    "    )\n",
    "    \n",
    "    # Load the model\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        checkpoint_or_path, local_files_only=local_files_only\n",
    "    )\n",
    "    \n",
    "    # Create a text classification pipeline\n",
    "    pipe = TextClassificationPipeline(model=model, tokenizer=tokenizer, top_k=None)\n",
    "    \n",
    "    preds = []\n",
    "    for out in tqdm(pipe(KeyDataset(dataset, \"text\"), **tokenizer_kwargs)):\n",
    "        if mode == \"label\":\n",
    "            preds.append(out[0][\"label\"])  # Append the predicted label\n",
    "        elif mode == \"proba\":\n",
    "            out.sort(key=lambda x: x[\"label\"])\n",
    "            preds.append([class_[\"score\"] for class_ in out])  # Append the predicted probabilities for each class\n",
    "    \n",
    "    return np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38bd939-5820-4bc7-bb41-4c31fd3ac941",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"../src3/detector/josefina-sexism-detection-vf\"\n",
    "test_preds = predict_from_transformer(sexism_data.dataset[\"test\"], \n",
    "                                      chekpoint_or_path=model,\n",
    "                                      mode=\"proba\",\n",
    "                                      local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e7457c-35b5-4e48-9ea1-6727603370b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "def plot_binary_roc_curve(y, y_score):\n",
    "    \"\"\"\n",
    "    Plots the binary ROC curve based on the true labels and predicted scores.\n",
    "\n",
    "    Args:\n",
    "        - y (array-like): The true labels.\n",
    "        - y_score (array-like): The predicted scores.\n",
    "\n",
    "    \"\"\"\n",
    "    # Compute the false positive rate, true positive rate, and thresholds for the ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(y, y_score)\n",
    "    \n",
    "    # Create a plotly figure for the ROC curve\n",
    "    fig = px.area(\n",
    "        x=fpr, y=tpr,\n",
    "        title=f'ROC Curve (AUC={auc(fpr, tpr):.4f})',\n",
    "        labels=dict(x='False Positive Rate', y='True Positive Rate'),\n",
    "        width=700, height=500\n",
    "    )\n",
    "    \n",
    "    # Add a diagonal line to the plot\n",
    "    fig.add_shape(\n",
    "        type='line', line=dict(dash='dash'),\n",
    "        x0=0, x1=1, y0=0, y1=1\n",
    "    )\n",
    "    \n",
    "    # Compute the optimal threshold as the median of the true positive rate\n",
    "    optimal_threshold = np.median(tpr)\n",
    "    print(\"Best Threshold:\", optimal_threshold)\n",
    "    \n",
    "    # Add a vertical line for the optimal threshold\n",
    "    fig.add_shape(\n",
    "        type='line', line=dict(dash='dash', color=\"red\"),\n",
    "        x0=optimal_threshold, x1=optimal_threshold, y0=0, y1=1\n",
    "    )\n",
    "    \n",
    "    # Configure the plot axes\n",
    "    fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
    "    fig.update_xaxes(constrain='domain')\n",
    "    \n",
    "    # Show the plot\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01097744-fa69-4640-ae02-8b7e6791b9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_binary_roc_curve(\n",
    "    y=np.array(sexism_data.dataset[\"test\"][\"label\"]), \n",
    "    y_score=test_preds[:, 1]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bfc1d7-9b86-4a94-83bf-16f24bf8624e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Rosita - Sexism Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c68c5dc-7837-4dbf-baf2-ca35bb26324f",
   "metadata": {},
   "source": [
    "Rosita is our specialized model designed for the classification of sexist content into different types. Built upon the ROBERTA-base-bne architecture, Rosita excels at accurately identifying and categorizing instances of sexism in text. It focuses on classifying sexist content into specific types, including \"violent,\" \"hate,\" \"profanities,\" \"abuse,\" and \"sexually-explicit\". In this section, we will dive into the features and performance of Rosita, highlighting its effectiveness in classifying and understanding different types of sexist content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ad5777-f21b-4947-b9b6-1ff5c808f750",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Training with Original Spanish data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e74151-498c-4553-ab9a-d0fb6caf3d6d",
   "metadata": {},
   "source": [
    "In this subsection, we shift our focus to the original Spanish dataset. We analyze the performance of Rosita, the sexism classification model, on this dataset and proceed as with the previous model, but now calling the `SexismDataset` for the classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a42eea8-caa3-4aba-a321-8e5ccc8d42ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_es_sexist = data_es.query(\"type != 'non-sexist'\")\n",
    "sexism_data_es_sexist = SexismDataset(data_es_sexist, \n",
    "                                      task_name=\"classification\", \n",
    "                                      model_checkpoint=MODEL_CHECKPOINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4997ba69-1557-4ded-abd4-09d880e3f88d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 526,
     "referenced_widgets": [
      "bfc7e46d5c9849f3af713c1ecf62fe5c",
      "3bbb274e4f4f405c812d7ff3b326137c",
      "3f93910c0b4d4a418d3e0732e1d32815",
      "ffd129b1ccfc46548c3467bfb999cadb",
      "7746414a61944721b3057d6a7425c855",
      "18e9e3ba66124711b379c88d6929cd27",
      "553660e45fe74aecb26adc13da79dc91",
      "d8e493c29e3e42ecb28aa9b22056053e",
      "1f37a5b45f73438d909bf80c78335171",
      "998a15d487ca4c03a147defa20b25b5b",
      "3080f5f79b424e2bb39fcb92e7729f7c",
      "b84c83e2b60e41a385924e1a1f37a321",
      "52438570f856428e89cc3fde2659fb71",
      "4d3df7b8d9ca4baea8584801479a4d8a",
      "4a26cca341ab4486887ff1e7f08011d9",
      "2777cefe85e8437dacb503bf668ae9fc",
      "e48fa21c3e7e49ba8aec137370b7fc6a",
      "3eceaa07647445e59bd97eca37f54884",
      "f41df8d30a3a41fa973a73cc0a42ff05",
      "c52bf2e0310f4bf4820fd8afe677931e",
      "516c861518f74789b0001d8d9b43a619",
      "f9ccab3612e1408f8668fc1376574905",
      "c1d5bd09901b40e3a7806215b474fae9",
      "ace5130ec7ed4d97acb8004041dc2414",
      "96c16f2ae76b49c6bf4ae22ebe960335",
      "0bac769e3bb94da5b48da374a650ac66",
      "a59816293df1468fa99a8ecb2804d39c",
      "054fa35d78ac47f09334ef1bf238b99b",
      "44a4df7e0be64a89a8bdcfa5f74a03d8",
      "901c8eb320114bf7b024bb2fb16459ec",
      "30387d140958408ca3eab5d1a559d2b8",
      "4a4c7f5c5ea0435ab881fe18ef91918f",
      "b29f3bc4b0f343b8a894ba5d8502d43b"
     ]
    },
    "id": "0vugJWoyCKcs",
    "outputId": "02b9a663-636d-42e7-90a0-d493bc84e178"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfc7e46d5c9849f3af713c1ecf62fe5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3372 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b84c83e2b60e41a385924e1a1f37a321",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/674 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1d5bd09901b40e3a7806215b474fae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/450 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at PlanTL-GOB-ES/roberta-base-bne were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at PlanTL-GOB-ES/roberta-base-bne and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2028' max='2028' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2028/2028 31:30, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.851816</td>\n",
       "      <td>0.652819</td>\n",
       "      <td>0.641767</td>\n",
       "      <td>0.654242</td>\n",
       "      <td>0.633142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.871700</td>\n",
       "      <td>0.833491</td>\n",
       "      <td>0.691395</td>\n",
       "      <td>0.670194</td>\n",
       "      <td>0.710103</td>\n",
       "      <td>0.646217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.396600</td>\n",
       "      <td>1.019240</td>\n",
       "      <td>0.669139</td>\n",
       "      <td>0.667507</td>\n",
       "      <td>0.674510</td>\n",
       "      <td>0.665346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.396600</td>\n",
       "      <td>1.345137</td>\n",
       "      <td>0.685460</td>\n",
       "      <td>0.674401</td>\n",
       "      <td>0.694352</td>\n",
       "      <td>0.661430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.093300</td>\n",
       "      <td>1.474750</td>\n",
       "      <td>0.678042</td>\n",
       "      <td>0.663868</td>\n",
       "      <td>0.677734</td>\n",
       "      <td>0.653224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.029700</td>\n",
       "      <td>1.517440</td>\n",
       "      <td>0.678042</td>\n",
       "      <td>0.667211</td>\n",
       "      <td>0.686759</td>\n",
       "      <td>0.652865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final model evaluation:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3451370000839233, 'eval_accuracy': 0.685459940652819, 'eval_f1': 0.6744012860692031, 'eval_precision': 0.6943522738337897, 'eval_recall': 0.6614295967440181, 'eval_runtime': 19.5839, 'eval_samples_per_second': 34.416, 'eval_steps_per_second': 3.472, 'epoch': 6.0}\n",
      "\n",
      "Results over test data:\n",
      "{'test_loss': 1.5957179069519043, 'test_accuracy': 0.6533333333333333, 'test_f1': 0.6223921221987129, 'test_precision': 0.6313104105246734, 'test_recall': 0.6175612659726323, 'test_runtime': 13.144, 'test_samples_per_second': 34.236, 'test_steps_per_second': 3.424}\n"
     ]
    }
   ],
   "source": [
    "tagger_trainer_es = train_transformer(fancy_name=\"unicc-rosita-sexism-classification-v0\", \n",
    "                                      tokenized_dataset=sexism_data_es_sexist.tokenized, \n",
    "                                      model_name=MODEL_CHECKPOINT,\n",
    "                                      num_labels=sexism_data_es_sexist.num_labels,\n",
    "                                      tokenizer=sexism_data_es_sexist.tokenizer,\n",
    "                                      compute_metrics=sexism_data_es_sexist.build_compute_metrics()\n",
    "                                      hyper_params={\"epochs\":6},\n",
    "                                      evaluate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1aabef-1f01-4995-982a-8c4621204437",
   "metadata": {},
   "source": [
    "In the final evaluation, the model achieves an F1-score of 0.674, indicating a balanced trade-off between precision and recall. The precision value is 0.694, reflecting the model's ability to accurately classify instances of sexism, while the recall value of 0.661 suggests that the model captures a substantial portion of actual sexist instances.\n",
    "\n",
    "The results over the test data show a similar trend, with an F1-score of 0.622, precision of 0.631, and recall of 0.618. These metrics indicate that the model's performance generalizes reasonably well to unseen data, although there is a slight drop in performance compared to the validation set.\n",
    "\n",
    "Overall, the evaluation of Rosita on the original Spanish dataset highlights its effectiveness in classifying different types of sexism, as evidenced by the F1-score, precision, and recall metrics. However, further analysis and fine-tuning may be required to improve the model's performance and address any potential limitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "198573f6-6ebc-4a05-870c-808ef21f3e72",
   "metadata": {
    "id": "2qWMSJcpoSst"
   },
   "outputs": [],
   "source": [
    "tagger_trainer_es.save_model(\"../src3/tagger/rosita-sexism-classification-v0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869c7402-128e-4d8c-a1f7-85eb19189516",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Training with Also Translated data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9033e3-6322-4055-a31e-2aa51a8d4e5c",
   "metadata": {},
   "source": [
    "Now we evaluate the performance of Rosita on the translated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b14f9e2f-d7b4-4aac-93c8-c8a404a21aeb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "146a1611da604ef2a99c7bdb669b811b",
      "2868a55cef704463b82f9f80fe540a41",
      "1d60482949704bc8951dc09cea029f8d",
      "e81ddd7525e5413c969321c83deb8e45",
      "558d3af6a46942a0a4ada839e3b2abb3",
      "96d04ae38a06475cb03d78b07effe4ce",
      "16633c83543a477ab882594c8061c362",
      "c81cc2afefaa4f9a93b61849e58b4ca2",
      "a1206e24155648e898685c924561f4f6",
      "b005e73ef81246adad2e110f77daf0b3",
      "c2afdd55f00e43f6814b454b6a7d0b24",
      "6d101fa1c4f4490a943c13cf7357d9f2",
      "1965939a4d7f460a916d755aab14afd4",
      "3fd512a3f22341cea1b7de6321e2998b",
      "92589c26836d40b29237e9250539b213",
      "92e890f8d14344b58471e1c283136f4b",
      "89b53267552d49cc84e3f1c3ea1c5c5c",
      "66d39a47f92143a2b776ce494e51c404",
      "42171475d62e4a709b9f6f6a0b3dd264",
      "1395c703a4ca49c694be5fbd7daa6935",
      "8711056bfab84592b4a37d10748d7595",
      "988ea0b8929d422e8da04fa43ac458ae",
      "3fdbf879ebb046fea37567222c3ae4d4",
      "4fcdf4edc23042109ba9f92b1320f3fb",
      "b428e929c73d45ca8043f99d3b785bd6",
      "cc20afcba8c646e28249c0b0f42e81c9",
      "fba07350f30a4703b64405e23f65f66e",
      "d797295c770f4443aed751d53811eb61",
      "7438bfbd61ee46bea3b2d8a832c08637",
      "2c7a048f08914b80b27a04c179e1c7d8",
      "85f4acaa846147f8b65713596ca73c8e",
      "b800f036902d4d9180ef75dbcd1bb7db",
      "133cbc79321545a1ac60ef163472fa79"
     ]
    },
    "id": "b9SekEDFDsGm",
    "outputId": "72aa8e7c-fa9d-4d69-fbde-a90ce94c091c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "146a1611da604ef2a99c7bdb669b811b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11868 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d101fa1c4f4490a943c13cf7357d9f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2373 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fdbf879ebb046fea37567222c3ae4d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1583 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_data_sexist = data.query(\"language!='en' and type!='non-sexist'\")\n",
    "sexism_data_sexist = SexismDataset(full_data_sexist, \n",
    "                                   task_name=\"classification\", \n",
    "                                   model_checkpoint=MODEL_CHECKPOINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91ecba47-81a6-4082-9301-ba86ae354d2d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 446
    },
    "id": "oXV2Wc5yDnCN",
    "outputId": "63c472c1-f3fe-4b11-ec02-31696d4c6a28"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at PlanTL-GOB-ES/roberta-base-bne were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at PlanTL-GOB-ES/roberta-base-bne and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4748' max='4748' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4748/4748 1:12:06, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.005500</td>\n",
       "      <td>0.916657</td>\n",
       "      <td>0.657396</td>\n",
       "      <td>0.577131</td>\n",
       "      <td>0.613161</td>\n",
       "      <td>0.557523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.643300</td>\n",
       "      <td>0.956830</td>\n",
       "      <td>0.679309</td>\n",
       "      <td>0.601918</td>\n",
       "      <td>0.640519</td>\n",
       "      <td>0.581019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.219700</td>\n",
       "      <td>1.341244</td>\n",
       "      <td>0.665402</td>\n",
       "      <td>0.595388</td>\n",
       "      <td>0.613215</td>\n",
       "      <td>0.583015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.066400</td>\n",
       "      <td>1.647807</td>\n",
       "      <td>0.668352</td>\n",
       "      <td>0.595902</td>\n",
       "      <td>0.626016</td>\n",
       "      <td>0.577605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final model evaluation:\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9568303227424622, 'eval_accuracy': 0.6793088916982722, 'eval_f1': 0.6019178478496637, 'eval_precision': 0.6405186445881987, 'eval_recall': 0.581019067649878, 'eval_runtime': 69.3958, 'eval_samples_per_second': 34.195, 'eval_steps_per_second': 3.43, 'epoch': 4.0}\n",
      "\n",
      "Results over test data:\n",
      "{'test_loss': 0.97837233543396, 'test_accuracy': 0.6664560960202148, 'test_f1': 0.6056583488073766, 'test_precision': 0.6494338956086831, 'test_recall': 0.5832416779256636, 'test_runtime': 46.6336, 'test_samples_per_second': 33.945, 'test_steps_per_second': 3.41}\n"
     ]
    }
   ],
   "source": [
    "tagger_trainer = train_transformer(fancy_name=\"unicc-rosita-sexism-detection\", \n",
    "                                   tokenized_dataset=sexism_data_sexist.tokenized, \n",
    "                                   model_name=MODEL_CHECKPOINT,\n",
    "                                   num_labels=sexism_data_sexist.num_labels,\n",
    "                                   tokenizer=sexism_data_sexist.tokenizer,\n",
    "                                   compute_metrics=sexism_data_sexist.build_compute_metrics()\n",
    "                                   evaluate=True,\n",
    "                                   hyper_params={\"batch\":10})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6b6e4d-74f9-4c35-b896-95f406df0153",
   "metadata": {},
   "source": [
    "In comparing the results between training and evaluating Rosita on the original Spanish dataset and incorporating translated and synthetic instances, we observed a slight decrease in performance in the second task. We hypothesize that this decrease could be attributed to the challenge of homogenizing the different label sets from each data source. The combination of diverse data sources made it difficult to separate similar labels into distinct categories.\n",
    "\n",
    "The merging of labels from different sources may have introduced some noise and ambiguity into the training process, resulting in a marginal decrease in the F1-score. It is possible that the overlapping or conflicting labels affected the model's ability to learn and generalize effectively across the different types of sexism.\n",
    "\n",
    "To further improve the performance of the classification model, future work could focus on refining the label assignment process and exploring techniques to handle label heterogeneity. By carefully addressing these challenges and finding ways to better integrate and reconcile the different label sets, we may be able to mitigate the potential noise and ambiguity introduced by the combination of translated and synthetic instances. This could lead to improved performance and a more accurate classification of sexism in Spanish text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c9a335-b09c-4011-b796-3bcf13cbfb05",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Hyperparameter-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f739c58-bd6e-444c-9f4e-0f09b3477ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sexism_types_data_sample = SexismDataset(full_data_sexist, \n",
    "                                         task_name=\"classification\", \n",
    "                                         model_checkpoint=MODEL_CHECKPOINT,\n",
    "                                         max_instances=10000)\n",
    "\n",
    "fancy_name = \"\"\n",
    "best_run2 = hp_tune_transformer(fancy_name=fancy_name,\n",
    "                                model_name=MODEL_CHECKPOINT,\n",
    "                                tokenized_dataset=sexism_types_data_sample.tokenized,\n",
    "                                num_labels=sexism_types_data_sample.num_labels,\n",
    "                                tokenizer=sexism_types_data_sample.tokenizer,\n",
    "                                compute_metrics=sexism_types_data_sample.build_compute_metrics(),\n",
    "                                num_samples=8, \n",
    "                                cpus_per_trial=1, \n",
    "                                gpus_per_trial=2,\n",
    "                                report_to=\"wandb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00e846e-ffaa-41f3-82db-b6cde6b89a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, v in best_run2.hyperparameters.items():\n",
    "    setattr(tagger_trainer.args, n, v)\n",
    "\n",
    "tagger_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324b4b3b-787f-404f-9df2-7e0f723a54da",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger_trainer.save_model(\"../src3/detector/rosita-sexism-classification-vf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819bab4a-a9da-41e9-bfe5-85f2c93666a5",
   "metadata": {},
   "source": [
    "### ROC Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3268dec-72b7-4714-85ee-ec02637320dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the positive probabilities from the detector over the test set\n",
    "model = \"../src3/detector/rosita-sexism-classification\"\n",
    "test_preds2 = predict_from_transformer(sexism_data_sexist.dataset[\"test\"], \n",
    "                                       chekpoint_or_path=model,\n",
    "                                       mode=\"proba\",\n",
    "                                       local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02718e0-5328-4da5-8e0a-4ddab65039e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multiclass_roc_curve(y, y_score):\n",
    "    \"\"\"\n",
    "    Plots the Receiver Operating Characteristic (ROC) curve for multi-class classification.\n",
    "    \n",
    "    Parameters:\n",
    "    - y: True labels (array-like, shape [n_samples, n_classes])\n",
    "    - y_score: Predicted scores (array-like, shape [n_samples, n_classes])\n",
    "    \"\"\"\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y.ravel(), y_score.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "    # Compute macro-average ROC curve and ROC area\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(n_classes):\n",
    "        mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "    mean_tpr /= n_classes\n",
    "    fpr[\"macro\"] = all_fpr\n",
    "    tpr[\"macro\"] = mean_tpr\n",
    "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "    # Plot all ROC curves\n",
    "    data = []\n",
    "    \n",
    "    # Plot micro-average ROC curve\n",
    "    trace1 = go.Scatter(\n",
    "        x=fpr[\"micro\"],\n",
    "        y=tpr[\"micro\"],\n",
    "        mode='lines',\n",
    "        line=dict(color='deeppink', width=lw, dash='dot'),\n",
    "        name='micro-average ROC curve (area = {0:0.2f})'.format(roc_auc[\"micro\"])\n",
    "    )\n",
    "    data.append(trace1)\n",
    "\n",
    "    # Plot macro-average ROC curve\n",
    "    trace2 = go.Scatter(\n",
    "        x=fpr[\"macro\"],\n",
    "        y=tpr[\"macro\"],\n",
    "        mode='lines',\n",
    "        line=dict(color='navy', width=lw, dash='dot'),\n",
    "        name='macro-average ROC curve (area = {0:0.2f})'.format(roc_auc[\"macro\"])\n",
    "    )\n",
    "    data.append(trace2)\n",
    "\n",
    "    colors = cycle([\"#c4d454\", \"#a08c88\", \"#fbd305\", \"#EEC3B9\", \"#418fde\"])\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        # Plot ROC curve for each class\n",
    "        trace = go.Scatter(\n",
    "            x=fpr[i],\n",
    "            y=tpr[i],\n",
    "            mode='lines',\n",
    "            line=dict(color=color, width=lw),\n",
    "            name='ROC curve of class {0} (area = {1:0.2f})'.format(i, roc_auc[i])\n",
    "        )\n",
    "        data.append(trace)\n",
    "\n",
    "    # Add a dashed line for reference\n",
    "    trace4 = go.Scatter(\n",
    "        x=[0, 1],\n",
    "        y=[0, 1],\n",
    "        mode='lines',\n",
    "        line=dict(color='black', width=lw, dash='dash'),\n",
    "        showlegend=False\n",
    "    )\n",
    "    data.append(trace4)\n",
    "\n",
    "    # Set layout for the plot\n",
    "    layout = go.Layout(\n",
    "        title='Some extension of Receiver operating characteristic to multi-class',\n",
    "        xaxis=dict(title='False Positive Rate'),\n",
    "        yaxis=dict(title='True Positive Rate')\n",
    "    )\n",
    "\n",
    "    # Create the figure and display the plot\n",
    "    fig = go.Figure(data=data, layout=layout)\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dec8cb0-21e4-4734-a135-ad919a8ba187",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_multiclass_roc_curve(\n",
    "    y=OneHotEncoder().fit_transform(np.array(sexism_data_sexist.dataset[\"test\"][\"label\"]).reshape(-1, 1)).toarray(), \n",
    "    y=label_binarize([0, 1, 2], classes=sexism_data_sexist.le.)\n",
    "    y_score=test_preds2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591352f5-e67e-4c45-9bf9-50163b728ce9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f809b9-e356-4602-895d-c245b1a820b8",
   "metadata": {},
   "source": [
    "\n",
    "Our experiments examined the performance of the models in the detection and classification tasks using both the Spanish dataset and the full dataset, which included translated and synthetic instances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "7a29285a-c07e-4b45-8082-5a56575cfcab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "partition=val<br>dataset=spanish<br>task=detection<br>metric=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "val",
         "marker": {
          "color": "#5BC3E3",
          "pattern": {
           "shape": ""
          }
         },
         "name": "val",
         "offsetgroup": "val",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "texttemplate": "%{y:.2f}",
         "type": "bar",
         "x": [
          "accuracy",
          "f1-score",
          "precision",
          "recall"
         ],
         "xaxis": "x3",
         "y": [
          0.787,
          0.782,
          0.725,
          0.848
         ],
         "yaxis": "y3"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "partition=val<br>dataset=spanish<br>task=classification<br>metric=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "val",
         "marker": {
          "color": "#5BC3E3",
          "pattern": {
           "shape": ""
          }
         },
         "name": "val",
         "offsetgroup": "val",
         "orientation": "v",
         "showlegend": false,
         "textposition": "auto",
         "texttemplate": "%{y:.2f}",
         "type": "bar",
         "x": [
          "accuracy",
          "f1-score",
          "precision",
          "recall"
         ],
         "xaxis": "x4",
         "y": [
          0.685,
          0.674,
          0.694,
          0.661
         ],
         "yaxis": "y4"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "partition=val<br>dataset=translated<br>task=detection<br>metric=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "val",
         "marker": {
          "color": "#5BC3E3",
          "pattern": {
           "shape": ""
          }
         },
         "name": "val",
         "offsetgroup": "val",
         "orientation": "v",
         "showlegend": false,
         "textposition": "auto",
         "texttemplate": "%{y:.2f}",
         "type": "bar",
         "x": [
          "accuracy",
          "f1-score",
          "precision",
          "recall"
         ],
         "xaxis": "x",
         "y": [
          0.801,
          0.79,
          0.751,
          0.834
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "partition=val<br>dataset=translated<br>task=classification<br>metric=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "val",
         "marker": {
          "color": "#5BC3E3",
          "pattern": {
           "shape": ""
          }
         },
         "name": "val",
         "offsetgroup": "val",
         "orientation": "v",
         "showlegend": false,
         "textposition": "auto",
         "texttemplate": "%{y:.2f}",
         "type": "bar",
         "x": [
          "accuracy",
          "f1-score",
          "precision",
          "recall"
         ],
         "xaxis": "x2",
         "y": [
          0.679,
          0.602,
          0.641,
          0.581
         ],
         "yaxis": "y2"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "partition=test<br>dataset=spanish<br>task=detection<br>metric=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "test",
         "marker": {
          "color": "#ea544d",
          "pattern": {
           "shape": ""
          }
         },
         "name": "test",
         "offsetgroup": "test",
         "orientation": "v",
         "showlegend": true,
         "textposition": "auto",
         "texttemplate": "%{y:.2f}",
         "type": "bar",
         "x": [
          "accuracy",
          "f1-score",
          "precision",
          "recall"
         ],
         "xaxis": "x3",
         "y": [
          0.782,
          0.776,
          0.721,
          0.84
         ],
         "yaxis": "y3"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "partition=test<br>dataset=spanish<br>task=classification<br>metric=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "test",
         "marker": {
          "color": "#ea544d",
          "pattern": {
           "shape": ""
          }
         },
         "name": "test",
         "offsetgroup": "test",
         "orientation": "v",
         "showlegend": false,
         "textposition": "auto",
         "texttemplate": "%{y:.2f}",
         "type": "bar",
         "x": [
          "accuracy",
          "f1-score",
          "precision",
          "recall"
         ],
         "xaxis": "x4",
         "y": [
          0.653,
          0.622,
          0.631,
          0.618
         ],
         "yaxis": "y4"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "partition=test<br>dataset=translated<br>task=detection<br>metric=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "test",
         "marker": {
          "color": "#ea544d",
          "pattern": {
           "shape": ""
          }
         },
         "name": "test",
         "offsetgroup": "test",
         "orientation": "v",
         "showlegend": false,
         "textposition": "auto",
         "texttemplate": "%{y:.2f}",
         "type": "bar",
         "x": [
          "accuracy",
          "f1-score",
          "precision",
          "recall"
         ],
         "xaxis": "x",
         "y": [
          0.797,
          0.784,
          0.752,
          0.82
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "hovertemplate": "partition=test<br>dataset=translated<br>task=classification<br>metric=%{x}<br>value=%{y}<extra></extra>",
         "legendgroup": "test",
         "marker": {
          "color": "#ea544d",
          "pattern": {
           "shape": ""
          }
         },
         "name": "test",
         "offsetgroup": "test",
         "orientation": "v",
         "showlegend": false,
         "textposition": "auto",
         "texttemplate": "%{y:.2f}",
         "type": "bar",
         "x": [
          "accuracy",
          "f1-score",
          "precision",
          "recall"
         ],
         "xaxis": "x2",
         "y": [
          0.665,
          0.606,
          0.649,
          0.583
         ],
         "yaxis": "y2"
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {},
          "showarrow": false,
          "text": "Detection Task",
          "x": 0.2375,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {},
          "showarrow": false,
          "text": "Classification Task",
          "x": 0.7424999999999999,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {},
          "showarrow": false,
          "text": "Translated Dataset",
          "textangle": 90,
          "x": 0.98,
          "xanchor": "left",
          "xref": "paper",
          "y": 0.225,
          "yanchor": "middle",
          "yref": "paper"
         },
         {
          "font": {},
          "showarrow": false,
          "text": "Spanish Dataset",
          "textangle": 90,
          "x": 0.98,
          "xanchor": "left",
          "xref": "paper",
          "y": 0.775,
          "yanchor": "middle",
          "yref": "paper"
         }
        ],
        "autosize": false,
        "barmode": "group",
        "height": 600,
        "legend": {
         "title": {
          "text": "partition"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "width": 700,
        "xaxis": {
         "anchor": "y",
         "autorange": true,
         "domain": [
          0,
          0.475
         ],
         "range": [
          -0.5,
          3.5
         ],
         "title": {
          "text": "metric"
         },
         "type": "category"
        },
        "xaxis2": {
         "anchor": "y2",
         "autorange": true,
         "domain": [
          0.505,
          0.98
         ],
         "matches": "x",
         "range": [
          -0.5,
          3.5
         ],
         "title": {
          "text": "metric"
         },
         "type": "category"
        },
        "xaxis3": {
         "anchor": "y3",
         "autorange": true,
         "domain": [
          0,
          0.475
         ],
         "matches": "x",
         "range": [
          -0.5,
          3.5
         ],
         "showticklabels": false,
         "type": "category"
        },
        "xaxis4": {
         "anchor": "y4",
         "autorange": true,
         "domain": [
          0.505,
          0.98
         ],
         "matches": "x",
         "range": [
          -0.5,
          3.5
         ],
         "showticklabels": false,
         "type": "category"
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          0.45
         ],
         "range": [
          0.5,
          0.9
         ],
         "title": {
          "text": "value"
         },
         "type": "linear"
        },
        "yaxis2": {
         "anchor": "x2",
         "domain": [
          0,
          0.45
         ],
         "matches": "y",
         "showticklabels": false,
         "type": "linear"
        },
        "yaxis3": {
         "anchor": "x3",
         "domain": [
          0.55,
          1
         ],
         "matches": "y",
         "range": [
          0.5,
          0.9
         ],
         "title": {
          "text": "value"
         },
         "type": "linear"
        },
        "yaxis4": {
         "anchor": "x4",
         "domain": [
          0.55,
          1
         ],
         "matches": "y",
         "showticklabels": false,
         "type": "linear"
        }
       }
      },
      "image/png": "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",
      "text/html": [
       "<div>                            <div id=\"c1efcd5c-86d7-4c50-82af-07a020b59863\" class=\"plotly-graph-div\" style=\"height:600px; width:700px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"c1efcd5c-86d7-4c50-82af-07a020b59863\")) {                    Plotly.newPlot(                        \"c1efcd5c-86d7-4c50-82af-07a020b59863\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"partition=val<br>dataset=spanish<br>task=detection<br>metric=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"val\",\"marker\":{\"color\":\"#5BC3E3\",\"pattern\":{\"shape\":\"\"}},\"name\":\"val\",\"offsetgroup\":\"val\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"texttemplate\":\"%{y:.2f}\",\"x\":[\"accuracy\",\"f1-score\",\"precision\",\"recall\"],\"xaxis\":\"x3\",\"y\":[0.787,0.782,0.725,0.848],\"yaxis\":\"y3\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"partition=val<br>dataset=spanish<br>task=classification<br>metric=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"val\",\"marker\":{\"color\":\"#5BC3E3\",\"pattern\":{\"shape\":\"\"}},\"name\":\"val\",\"offsetgroup\":\"val\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"auto\",\"texttemplate\":\"%{y:.2f}\",\"x\":[\"accuracy\",\"f1-score\",\"precision\",\"recall\"],\"xaxis\":\"x4\",\"y\":[0.685,0.674,0.694,0.661],\"yaxis\":\"y4\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"partition=val<br>dataset=translated<br>task=detection<br>metric=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"val\",\"marker\":{\"color\":\"#5BC3E3\",\"pattern\":{\"shape\":\"\"}},\"name\":\"val\",\"offsetgroup\":\"val\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"auto\",\"texttemplate\":\"%{y:.2f}\",\"x\":[\"accuracy\",\"f1-score\",\"precision\",\"recall\"],\"xaxis\":\"x\",\"y\":[0.801,0.79,0.751,0.834],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"partition=val<br>dataset=translated<br>task=classification<br>metric=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"val\",\"marker\":{\"color\":\"#5BC3E3\",\"pattern\":{\"shape\":\"\"}},\"name\":\"val\",\"offsetgroup\":\"val\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"auto\",\"texttemplate\":\"%{y:.2f}\",\"x\":[\"accuracy\",\"f1-score\",\"precision\",\"recall\"],\"xaxis\":\"x2\",\"y\":[0.679,0.602,0.641,0.581],\"yaxis\":\"y2\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"partition=test<br>dataset=spanish<br>task=detection<br>metric=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"test\",\"marker\":{\"color\":\"#ea544d\",\"pattern\":{\"shape\":\"\"}},\"name\":\"test\",\"offsetgroup\":\"test\",\"orientation\":\"v\",\"showlegend\":true,\"textposition\":\"auto\",\"texttemplate\":\"%{y:.2f}\",\"x\":[\"accuracy\",\"f1-score\",\"precision\",\"recall\"],\"xaxis\":\"x3\",\"y\":[0.782,0.776,0.721,0.84],\"yaxis\":\"y3\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"partition=test<br>dataset=spanish<br>task=classification<br>metric=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"test\",\"marker\":{\"color\":\"#ea544d\",\"pattern\":{\"shape\":\"\"}},\"name\":\"test\",\"offsetgroup\":\"test\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"auto\",\"texttemplate\":\"%{y:.2f}\",\"x\":[\"accuracy\",\"f1-score\",\"precision\",\"recall\"],\"xaxis\":\"x4\",\"y\":[0.653,0.622,0.631,0.618],\"yaxis\":\"y4\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"partition=test<br>dataset=translated<br>task=detection<br>metric=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"test\",\"marker\":{\"color\":\"#ea544d\",\"pattern\":{\"shape\":\"\"}},\"name\":\"test\",\"offsetgroup\":\"test\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"auto\",\"texttemplate\":\"%{y:.2f}\",\"x\":[\"accuracy\",\"f1-score\",\"precision\",\"recall\"],\"xaxis\":\"x\",\"y\":[0.797,0.784,0.752,0.82],\"yaxis\":\"y\",\"type\":\"bar\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"partition=test<br>dataset=translated<br>task=classification<br>metric=%{x}<br>value=%{y}<extra></extra>\",\"legendgroup\":\"test\",\"marker\":{\"color\":\"#ea544d\",\"pattern\":{\"shape\":\"\"}},\"name\":\"test\",\"offsetgroup\":\"test\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"auto\",\"texttemplate\":\"%{y:.2f}\",\"x\":[\"accuracy\",\"f1-score\",\"precision\",\"recall\"],\"xaxis\":\"x2\",\"y\":[0.665,0.606,0.649,0.583],\"yaxis\":\"y2\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.475],\"title\":{\"text\":\"metric\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,0.45],\"title\":{\"text\":\"value\"},\"range\":[0.5,0.9]},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.505,0.98],\"matches\":\"x\",\"title\":{\"text\":\"metric\"}},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,0.45],\"matches\":\"y\",\"showticklabels\":false},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.0,0.475],\"matches\":\"x\",\"showticklabels\":false},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.55,1.0],\"matches\":\"y\",\"title\":{\"text\":\"value\"},\"range\":[0.5,0.9]},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.505,0.98],\"matches\":\"x\",\"showticklabels\":false},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.55,1.0],\"matches\":\"y\",\"showticklabels\":false},\"annotations\":[{\"font\":{},\"showarrow\":false,\"text\":\"Detection Task\",\"x\":0.2375,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{},\"showarrow\":false,\"text\":\"Classification Task\",\"x\":0.7424999999999999,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{},\"showarrow\":false,\"text\":\"Translated Dataset\",\"textangle\":90,\"x\":0.98,\"xanchor\":\"left\",\"xref\":\"paper\",\"y\":0.225,\"yanchor\":\"middle\",\"yref\":\"paper\"},{\"font\":{},\"showarrow\":false,\"text\":\"Spanish Dataset\",\"textangle\":90,\"x\":0.98,\"xanchor\":\"left\",\"xref\":\"paper\",\"y\":0.775,\"yanchor\":\"middle\",\"yref\":\"paper\"}],\"legend\":{\"title\":{\"text\":\"partition\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"group\",\"autosize\":false,\"width\":700,\"height\":600},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('c1efcd5c-86d7-4c50-82af-07a020b59863');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = pd.MultiIndex.from_tuples([(\"detection\", \"spanish\"), \n",
    "                           (\"detection\", \"translated\"), \n",
    "                           (\"classification\", \"spanish\"), \n",
    "                           (\"classification\", \"translated\")], names=[\"task\", \"dataset\"])\n",
    "cols = pd.MultiIndex.from_tuples([(\"accuracy\", \"val\"), \n",
    "                                  (\"accuracy\", \"test\"), \n",
    "                                  (\"f1-score\", \"val\"), \n",
    "                                  (\"f1-score\", \"test\"),\n",
    "                                  (\"precision\", \"val\"), \n",
    "                                  (\"precision\", \"test\"), \n",
    "                                  (\"recall\", \"val\"), \n",
    "                                  (\"recall\", \"test\")], names=[\"metric\", \"partition\"])\n",
    "results = pd.DataFrame(data=[\n",
    "    [ 0.787, 0.782, 0.782, 0.776, 0.725, 0.721, 0.848, 0.840 ],\n",
    "    [ 0.801, 0.797, 0.790, 0.784, 0.751, 0.752, 0.834, 0.820 ],\n",
    "    [ 0.685, 0.653, 0.674, 0.622, 0.694, 0.631, 0.661, 0.618 ],\n",
    "    [ 0.679, 0.665, 0.602, 0.606, 0.641, 0.649, 0.581, 0.583 ]\n",
    "], index=idx, columns=cols)\n",
    "\n",
    "res = results.melt(ignore_index=False).reset_index()\n",
    "\n",
    "fig = px.bar(\n",
    "    res, \n",
    "    x=\"metric\", \n",
    "    y=\"value\", \n",
    "    color=\"partition\", \n",
    "    color_discrete_sequence = [BLUE2, RED],\n",
    "    facet_col=\"task\", \n",
    "    facet_row=\"dataset\",         \n",
    "    facet_row_spacing=0.1, \n",
    "    facet_col_spacing=0.03,\n",
    "    barmode=\"group\", \n",
    "    range_y=(0.5, 0.9), \n",
    "    text_auto='.2f',\n",
    "    category_orders={\"task\": [\"detection\", \"classification\"]}\n",
    ")\n",
    "\n",
    "fig.for_each_annotation(lambda a: a.update(text=\" \".join(reversed(a.text.split(\"=\"))).title()))\n",
    "\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=700,\n",
    "    height=600,)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7ded86-8099-42f8-9151-7c40411fe731",
   "metadata": {},
   "source": [
    "In the detection task, the model trained on the Spanish dataset achieved F1 scores of 0.782 on the validation set and 0.776 on the test set. However, when incorporating the translated and synthetic instances, the F1 scores notably improved to 0.790 on the validation set and 0.784 on the test set. These results demonstrate that including additional data sources did not compromise the model's performance but instead led to significant improvements in detecting the target content.\n",
    "\n",
    "In the classification task, the model trained on the Spanish dataset achieved F1 scores of 0.674 on the validation set and 0.622 on the test set. Upon incorporating the translated and synthetic instances, there was a slight decrease in the F1 scores, resulting in scores of 0.602 on the validation set and 0.606 on the test set. However, it is worth noting that the F1 scores remained relatively stable, indicating that the model's performance was not significantly impacted.\n",
    "\n",
    "We hypothesize that the decrease in the classification task may be attributed to the challenge of homogenizing label sets from different data sources, introducing noise and ambiguity during the training process. Future work could focus on refining the label assignment process and exploring techniques to handle label heterogeneity, potentially resulting in improved performance for the classification model.\n",
    "\n",
    "Overall, our experiments demonstrate the effectiveness of leveraging translated and synthetic instances to enhance the performance of the models. The inclusion of additional data sources led to notable improvements in the detection task and maintained relatively stable results in the classification task. These findings highlight the value of using large language models to obtain labeled instances for text classification in languages with limited labeled resources. By overcoming the limitations of scarce labeled data, this approach opens up new possibilities for applying artificial intelligence and machine learning in diverse linguistic contexts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
